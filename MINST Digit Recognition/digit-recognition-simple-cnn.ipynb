{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020171,
     "end_time": "2021-01-10T17:46:24.300956",
     "exception": false,
     "start_time": "2021-01-10T17:46:24.280785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here's my attempt at making a simple CNN to train and make predictions on the MINST digits dataset.  We'll start off by importing the libraries and functions we'll be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-10T17:46:24.347925Z",
     "iopub.status.busy": "2021-01-10T17:46:24.347303Z",
     "iopub.status.idle": "2021-01-10T17:46:30.110183Z",
     "shell.execute_reply": "2021-01-10T17:46:30.109482Z"
    },
    "papermill": {
     "duration": 5.790176,
     "end_time": "2021-01-10T17:46:30.110295",
     "exception": false,
     "start_time": "2021-01-10T17:46:24.320119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019232,
     "end_time": "2021-01-10T17:46:30.148955",
     "exception": false,
     "start_time": "2021-01-10T17:46:30.129723",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we gotta import the data.  Kaggle stores it in the folders below, from which we import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-10T17:46:30.194581Z",
     "iopub.status.busy": "2021-01-10T17:46:30.193842Z",
     "iopub.status.idle": "2021-01-10T17:46:35.913421Z",
     "shell.execute_reply": "2021-01-10T17:46:35.912649Z"
    },
    "papermill": {
     "duration": 5.745818,
     "end_time": "2021-01-10T17:46:35.913563",
     "exception": false,
     "start_time": "2021-01-10T17:46:30.167745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "(28000, 784)\n",
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0         0         0         0   \n",
      "3       0  ...         0         0         0         0         0         0   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "#Reads in the training and testing sets.  \n",
    "df = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\n",
    "test =  pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\") #Won't see this again until later\n",
    "\n",
    "print(df.shape)\n",
    "print(test.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019104,
     "end_time": "2021-01-10T17:46:35.952910",
     "exception": false,
     "start_time": "2021-01-10T17:46:35.933806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As seen above, these are datasets of pixels by image, with each row representing a seperate image of 784 pixels (likely 28 high X 28 wide). The training set contains 42000 images, while the testing set contains 28000. This appears to be monohromatic, as there is only one layer. Were they not black and white, we could expect three different sets of values for each pixel, representing red, green, and blue.\n",
    "\n",
    "The training set has an extra column relating to the actual digit drawn for each image (the labels). Going forward, that is going to be very important information but we need to seperate it out so we only have pixel data in the training set. Below, the labels are sectioned off into their own list, and the corrisponding column is dropped from the training set.  We also get the counts of each different label, which will be helpful to know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T17:46:36.080437Z",
     "iopub.status.busy": "2021-01-10T17:46:36.079418Z",
     "iopub.status.idle": "2021-01-10T17:46:36.090842Z",
     "shell.execute_reply": "2021-01-10T17:46:36.090064Z"
    },
    "papermill": {
     "duration": 0.117317,
     "end_time": "2021-01-10T17:46:36.090990",
     "exception": false,
     "start_time": "2021-01-10T17:46:35.973673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    4684\n",
      "7    4401\n",
      "3    4351\n",
      "9    4188\n",
      "2    4177\n",
      "6    4137\n",
      "0    4132\n",
      "4    4072\n",
      "8    4063\n",
      "5    3795\n",
      "Name: label, dtype: int64\n",
      "Baseline Accuracy: 0.112\n"
     ]
    }
   ],
   "source": [
    "#Makes a list of the actual digits drawn for each image, then get's rid of that column from the training set\n",
    "labels = df[\"label\"]\n",
    "X = df.drop('label', axis = 1)\n",
    "print(labels.value_counts())\n",
    "\n",
    "print(\"Baseline Accuracy: \" + str(round(labels.value_counts().max()/labels.value_counts().sum(),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019625,
     "end_time": "2021-01-10T17:46:36.131585",
     "exception": false,
     "start_time": "2021-01-10T17:46:36.111960",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Above are the value counts for each label.  As you can see, it's fairly uniformly distributed, although there are some differences between categories.  Having a uniform distribution makes categorical classification a bit easier.  We also now know the base accuracy we need to achieve with the model to do better than just guessing the most common category every time (the number 1 in this case).  If the model does better than that, then it's a fair bet it's actually learnng from the imagery.\n",
    "\n",
    "Now let's find the range of potential values for each pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T17:46:36.179127Z",
     "iopub.status.busy": "2021-01-10T17:46:36.178248Z",
     "iopub.status.idle": "2021-01-10T17:46:36.251701Z",
     "shell.execute_reply": "2021-01-10T17:46:36.251219Z"
    },
    "papermill": {
     "duration": 0.1,
     "end_time": "2021-01-10T17:46:36.251804",
     "exception": false,
     "start_time": "2021-01-10T17:46:36.151804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(X.values.max())\n",
    "print(X.values.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020454,
     "end_time": "2021-01-10T17:46:36.293055",
     "exception": false,
     "start_time": "2021-01-10T17:46:36.272601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Pretty standard configuration: 0 is black, 255 is white.  We should adjust the values so they fall between 0 and 1, which makes it easier for the model to handle later.  We should also reshape and re-type the data to the required format.  Let's wrap it all up in a function.\n",
    "\n",
    "Note: Keras has built-in ways to do this stuff, but here it is anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T17:46:36.343098Z",
     "iopub.status.busy": "2021-01-10T17:46:36.342419Z",
     "iopub.status.idle": "2021-01-10T17:46:37.180130Z",
     "shell.execute_reply": "2021-01-10T17:46:37.179514Z"
    },
    "papermill": {
     "duration": 0.86632,
     "end_time": "2021-01-10T17:46:37.180272",
     "exception": false,
     "start_time": "2021-01-10T17:46:36.313952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "<class 'numpy.ndarray'>\n",
      "(42000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#Normalizes values in dataframe to 0-1, and reshapes it to the required dimensions \n",
    "def normalizeANDreshape(df, minimum, maximum): \n",
    "    diff = maximum - minimum\n",
    "    zero_min = df - minimum\n",
    "    adjusted = zero_min/diff\n",
    "    \n",
    "    shaped = adjusted.values.reshape(-1,28,28,1) #the width and height of the images, 1 layer deep because it's monochromatic (would be 3 if it contained RGB values)\n",
    "    \n",
    "    return shaped\n",
    "\n",
    "print(np.max(normalizeANDreshape(X, 0, 255)))\n",
    "print(np.min(normalizeANDreshape(X, 0, 255)))\n",
    "print(type(normalizeANDreshape(X, 0, 255)))\n",
    "print(normalizeANDreshape(X, 0, 255).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021829,
     "end_time": "2021-01-10T17:46:37.224352",
     "exception": false,
     "start_time": "2021-01-10T17:46:37.202523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As you can see, we now have a function that will get the image data ready for us.\n",
    "\n",
    "Now we need to process the labels, i.e. get dummy variables, to train the model with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T17:46:37.274063Z",
     "iopub.status.busy": "2021-01-10T17:46:37.273177Z",
     "iopub.status.idle": "2021-01-10T17:46:37.290662Z",
     "shell.execute_reply": "2021-01-10T17:46:37.291171Z"
    },
    "papermill": {
     "duration": 0.044811,
     "end_time": "2021-01-10T17:46:37.291310",
     "exception": false,
     "start_time": "2021-01-10T17:46:37.246499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9\n",
       "0  0  1  0  0  0  0  0  0  0  0\n",
       "1  1  0  0  0  0  0  0  0  0  0\n",
       "2  0  1  0  0  0  0  0  0  0  0\n",
       "3  0  0  0  0  1  0  0  0  0  0\n",
       "4  1  0  0  0  0  0  0  0  0  0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dummy lables in a dataframe\n",
    "y = pd.get_dummies(labels)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02283,
     "end_time": "2021-01-10T17:46:37.336865",
     "exception": false,
     "start_time": "2021-01-10T17:46:37.314035",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now to train this model well (and help avoid overfitting) we need to section off some of the training data into a validation set.  This way the model has some way to evaluate itself independent of the data it's using to train as it trains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T17:46:37.401235Z",
     "iopub.status.busy": "2021-01-10T17:46:37.399542Z",
     "iopub.status.idle": "2021-01-10T17:46:37.960044Z",
     "shell.execute_reply": "2021-01-10T17:46:37.958615Z"
    },
    "papermill": {
     "duration": 0.600508,
     "end_time": "2021-01-10T17:46:37.960166",
     "exception": false,
     "start_time": "2021-01-10T17:46:37.359658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Splits into training and validation sets.  Uses 20% of data as validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(normalizeANDreshape(X, 0, 255), y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021952,
     "end_time": "2021-01-10T17:46:38.004631",
     "exception": false,
     "start_time": "2021-01-10T17:46:37.982679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now this dataset is small enough (~122 MB) to fit into working memory, so we don't need to bother with configuring up directories to process it in chunks.  We will however want to augment it a bit.  \n",
    "\n",
    "These images are very small.  Also, if you go look at images of what these numbers look like (sorry for not including examples in here), you'll see that all of the numbers are fairly standard: right side up, not mirrored, not too tilted, etc.  Thus, we shouldn't need to do too much to avoid overfitting; we'll just shift things around, rotate slightly, and zoom a bit.\n",
    "\n",
    "Note: we do not want to augment the testing or the validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T17:46:38.057164Z",
     "iopub.status.busy": "2021-01-10T17:46:38.055944Z",
     "iopub.status.idle": "2021-01-10T17:46:38.142173Z",
     "shell.execute_reply": "2021-01-10T17:46:38.141566Z"
    },
    "papermill": {
     "duration": 0.114584,
     "end_time": "2021-01-10T17:46:38.142279",
     "exception": false,
     "start_time": "2021-01-10T17:46:38.027695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Augments the data with some rotated, shifted, and zoomed images\n",
    "augment = ImageDataGenerator(rotation_range = 15,\n",
    "                                  width_shift_range = 0.35,\n",
    "                                  height_shift_range = 0.35,\n",
    "                                  zoom_range = 0.2,\n",
    "                                  )\n",
    "augment.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022857,
     "end_time": "2021-01-10T17:46:38.187993",
     "exception": false,
     "start_time": "2021-01-10T17:46:38.165136",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we need to make the model.  As hinted at in the title, it's going to be a simple convoluted neural network (CNN).  Below is a function that will create the framework.  Lot's of ways to do this, and the images are fairly simple and small, so we shouldn't need too complex a network to get good results; below is one possiblity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T17:46:38.247670Z",
     "iopub.status.busy": "2021-01-10T17:46:38.246928Z",
     "iopub.status.idle": "2021-01-10T17:46:41.415721Z",
     "shell.execute_reply": "2021-01-10T17:46:41.413225Z"
    },
    "papermill": {
     "duration": 3.205666,
     "end_time": "2021-01-10T17:46:41.415881",
     "exception": false,
     "start_time": "2021-01-10T17:46:38.210215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        1088      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 128)         32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 182,538\n",
      "Trainable params: 182,410\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Sets the model architecture\n",
    "#Won't into how this works heree\n",
    "def makeCNN(shape):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (4,4), padding = 'same', activation = 'relu', input_shape = shape))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', activation = 'relu'))\n",
    "\n",
    "    model.add(Conv2D(filters = 128, kernel_size = (2,2), padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "    return model\n",
    "    \n",
    "#Displays a summary of the model\n",
    "model = makeCNN((28, 28, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.041037,
     "end_time": "2021-01-10T17:46:41.481490",
     "exception": false,
     "start_time": "2021-01-10T17:46:41.440453",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We now have a model framework with about 182k parameters.  Next, we need to compile it.  We'll try using the 'Adam' optomizer function, which will adapt the learning rate, along with categorical crossentropy for loss (becuase we are looking for categorical classification), and measure accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T17:46:41.546790Z",
     "iopub.status.busy": "2021-01-10T17:46:41.545801Z",
     "iopub.status.idle": "2021-01-10T17:46:41.553198Z",
     "shell.execute_reply": "2021-01-10T17:46:41.552610Z"
    },
    "papermill": {
     "duration": 0.043499,
     "end_time": "2021-01-10T17:46:41.553303",
     "exception": false,
     "start_time": "2021-01-10T17:46:41.509804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Compiles the model\n",
    "model.compile(optimizer = Adam(), #Default learning rate is 0.001\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022198,
     "end_time": "2021-01-10T17:46:41.599435",
     "exception": false,
     "start_time": "2021-01-10T17:46:41.577237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "All that's left is to train it.  We'll choose 50 epochs and a batch size of 64.  The images are pretty small, so this shouldn't take too long.  Could probably even do K-fold validation in a reasonable time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T17:46:41.653544Z",
     "iopub.status.busy": "2021-01-10T17:46:41.652394Z",
     "iopub.status.idle": "2021-01-10T17:57:01.810791Z",
     "shell.execute_reply": "2021-01-10T17:57:01.809659Z"
    },
    "papermill": {
     "duration": 620.188157,
     "end_time": "2021-01-10T17:57:01.810915",
     "exception": false,
     "start_time": "2021-01-10T17:46:41.622758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "525/525 [==============================] - 12s 23ms/step - loss: 1.0487 - accuracy: 0.6402 - val_loss: 0.1610 - val_accuracy: 0.9662\n",
      "Epoch 2/50\n",
      "525/525 [==============================] - 11s 21ms/step - loss: 0.3711 - accuracy: 0.8875 - val_loss: 0.0825 - val_accuracy: 0.9777\n",
      "Epoch 3/50\n",
      "525/525 [==============================] - 12s 23ms/step - loss: 0.2592 - accuracy: 0.9207 - val_loss: 0.0674 - val_accuracy: 0.9798\n",
      "Epoch 4/50\n",
      "525/525 [==============================] - 11s 21ms/step - loss: 0.2237 - accuracy: 0.9335 - val_loss: 0.0584 - val_accuracy: 0.9849\n",
      "Epoch 5/50\n",
      "525/525 [==============================] - 13s 25ms/step - loss: 0.1957 - accuracy: 0.9438 - val_loss: 0.0420 - val_accuracy: 0.9886\n",
      "Epoch 6/50\n",
      "525/525 [==============================] - 13s 24ms/step - loss: 0.1718 - accuracy: 0.9488 - val_loss: 0.0510 - val_accuracy: 0.9865\n",
      "Epoch 7/50\n",
      "525/525 [==============================] - 11s 22ms/step - loss: 0.1633 - accuracy: 0.9523 - val_loss: 0.0394 - val_accuracy: 0.9902\n",
      "Epoch 8/50\n",
      "525/525 [==============================] - 12s 23ms/step - loss: 0.1554 - accuracy: 0.9541 - val_loss: 0.0408 - val_accuracy: 0.9889\n",
      "Epoch 9/50\n",
      "525/525 [==============================] - 12s 23ms/step - loss: 0.1516 - accuracy: 0.9552 - val_loss: 0.0616 - val_accuracy: 0.9836\n",
      "Epoch 10/50\n",
      "525/525 [==============================] - 13s 26ms/step - loss: 0.1427 - accuracy: 0.9574 - val_loss: 0.0373 - val_accuracy: 0.9919\n",
      "Epoch 11/50\n",
      "525/525 [==============================] - 12s 24ms/step - loss: 0.1430 - accuracy: 0.9586 - val_loss: 0.0391 - val_accuracy: 0.9908\n",
      "Epoch 12/50\n",
      "525/525 [==============================] - 11s 22ms/step - loss: 0.1395 - accuracy: 0.9574 - val_loss: 0.0427 - val_accuracy: 0.9902\n",
      "Epoch 13/50\n",
      "525/525 [==============================] - 12s 23ms/step - loss: 0.1337 - accuracy: 0.9599 - val_loss: 0.0273 - val_accuracy: 0.9942\n",
      "Epoch 14/50\n",
      "525/525 [==============================] - 12s 23ms/step - loss: 0.1242 - accuracy: 0.9631 - val_loss: 0.0432 - val_accuracy: 0.9901\n",
      "Epoch 15/50\n",
      "525/525 [==============================] - 13s 24ms/step - loss: 0.1237 - accuracy: 0.9636 - val_loss: 0.0342 - val_accuracy: 0.9919\n",
      "Epoch 16/50\n",
      "525/525 [==============================] - 12s 22ms/step - loss: 0.1247 - accuracy: 0.9633 - val_loss: 0.0364 - val_accuracy: 0.9921\n",
      "Epoch 17/50\n",
      "525/525 [==============================] - 12s 23ms/step - loss: 0.1256 - accuracy: 0.9641 - val_loss: 0.0409 - val_accuracy: 0.9896\n",
      "Epoch 18/50\n",
      "525/525 [==============================] - 12s 23ms/step - loss: 0.1170 - accuracy: 0.9662 - val_loss: 0.0334 - val_accuracy: 0.9931\n",
      "Epoch 19/50\n",
      "525/525 [==============================] - 12s 23ms/step - loss: 0.1144 - accuracy: 0.9652 - val_loss: 0.0419 - val_accuracy: 0.9913\n",
      "Epoch 20/50\n",
      "525/525 [==============================] - 12s 24ms/step - loss: 0.1193 - accuracy: 0.9639 - val_loss: 0.0441 - val_accuracy: 0.9895\n",
      "Epoch 21/50\n",
      "525/525 [==============================] - 12s 23ms/step - loss: 0.1114 - accuracy: 0.9677 - val_loss: 0.0407 - val_accuracy: 0.9917\n",
      "Epoch 22/50\n",
      "525/525 [==============================] - 12s 22ms/step - loss: 0.1122 - accuracy: 0.9666 - val_loss: 0.0377 - val_accuracy: 0.9913\n",
      "Epoch 23/50\n",
      "525/525 [==============================] - 11s 21ms/step - loss: 0.1060 - accuracy: 0.9688 - val_loss: 0.0306 - val_accuracy: 0.9927\n",
      "Epoch 24/50\n",
      "525/525 [==============================] - 13s 25ms/step - loss: 0.1025 - accuracy: 0.9692 - val_loss: 0.0320 - val_accuracy: 0.9911\n",
      "Epoch 25/50\n",
      "525/525 [==============================] - 13s 24ms/step - loss: 0.1125 - accuracy: 0.9665 - val_loss: 0.0306 - val_accuracy: 0.9942\n",
      "Epoch 26/50\n",
      "525/525 [==============================] - 11s 21ms/step - loss: 0.1054 - accuracy: 0.9695 - val_loss: 0.0332 - val_accuracy: 0.9933\n",
      "Epoch 27/50\n",
      "525/525 [==============================] - 12s 22ms/step - loss: 0.1014 - accuracy: 0.9690 - val_loss: 0.0438 - val_accuracy: 0.9899\n",
      "Epoch 28/50\n",
      "525/525 [==============================] - 12s 23ms/step - loss: 0.1046 - accuracy: 0.9689 - val_loss: 0.0377 - val_accuracy: 0.9918\n",
      "Epoch 29/50\n",
      "525/525 [==============================] - 12s 23ms/step - loss: 0.1038 - accuracy: 0.9696 - val_loss: 0.0370 - val_accuracy: 0.9927\n",
      "Epoch 30/50\n",
      "525/525 [==============================] - 13s 25ms/step - loss: 0.1045 - accuracy: 0.9688 - val_loss: 0.0381 - val_accuracy: 0.9917\n",
      "Epoch 31/50\n",
      "525/525 [==============================] - 11s 22ms/step - loss: 0.1010 - accuracy: 0.9697 - val_loss: 0.0385 - val_accuracy: 0.9919\n",
      "Epoch 32/50\n",
      "525/525 [==============================] - 13s 24ms/step - loss: 0.0976 - accuracy: 0.9715 - val_loss: 0.0455 - val_accuracy: 0.9907\n",
      "Epoch 33/50\n",
      "525/525 [==============================] - 12s 22ms/step - loss: 0.1001 - accuracy: 0.9705 - val_loss: 0.0347 - val_accuracy: 0.9931\n",
      "Epoch 34/50\n",
      "525/525 [==============================] - 12s 22ms/step - loss: 0.0966 - accuracy: 0.9701 - val_loss: 0.0533 - val_accuracy: 0.9911\n",
      "Epoch 35/50\n",
      "525/525 [==============================] - 13s 26ms/step - loss: 0.0944 - accuracy: 0.9725 - val_loss: 0.0478 - val_accuracy: 0.9910\n",
      "Epoch 36/50\n",
      "525/525 [==============================] - 12s 23ms/step - loss: 0.1005 - accuracy: 0.9707 - val_loss: 0.0373 - val_accuracy: 0.9915\n",
      "Epoch 37/50\n",
      "525/525 [==============================] - 11s 21ms/step - loss: 0.1013 - accuracy: 0.9701 - val_loss: 0.0379 - val_accuracy: 0.9923\n",
      "Epoch 38/50\n",
      "525/525 [==============================] - 13s 26ms/step - loss: 0.0961 - accuracy: 0.9705 - val_loss: 0.0271 - val_accuracy: 0.9939\n",
      "Epoch 39/50\n",
      "525/525 [==============================] - 13s 25ms/step - loss: 0.0935 - accuracy: 0.9730 - val_loss: 0.0319 - val_accuracy: 0.9927\n",
      "Epoch 40/50\n",
      "525/525 [==============================] - 11s 22ms/step - loss: 0.0934 - accuracy: 0.9725 - val_loss: 0.0251 - val_accuracy: 0.9942\n",
      "Epoch 41/50\n",
      "525/525 [==============================] - 12s 23ms/step - loss: 0.0957 - accuracy: 0.9714 - val_loss: 0.0337 - val_accuracy: 0.9929\n",
      "Epoch 42/50\n",
      "525/525 [==============================] - 11s 21ms/step - loss: 0.0918 - accuracy: 0.9734 - val_loss: 0.0289 - val_accuracy: 0.9940\n",
      "Epoch 43/50\n",
      "525/525 [==============================] - 11s 21ms/step - loss: 0.0918 - accuracy: 0.9715 - val_loss: 0.0321 - val_accuracy: 0.9930\n",
      "Epoch 44/50\n",
      "525/525 [==============================] - 16s 30ms/step - loss: 0.0903 - accuracy: 0.9727 - val_loss: 0.0352 - val_accuracy: 0.9926\n",
      "Epoch 45/50\n",
      "525/525 [==============================] - 11s 21ms/step - loss: 0.0908 - accuracy: 0.9735 - val_loss: 0.0389 - val_accuracy: 0.9921\n",
      "Epoch 46/50\n",
      "525/525 [==============================] - 12s 22ms/step - loss: 0.0893 - accuracy: 0.9740 - val_loss: 0.0318 - val_accuracy: 0.9944\n",
      "Epoch 47/50\n",
      "525/525 [==============================] - 11s 22ms/step - loss: 0.0971 - accuracy: 0.9712 - val_loss: 0.0399 - val_accuracy: 0.9904\n",
      "Epoch 48/50\n",
      "525/525 [==============================] - 11s 22ms/step - loss: 0.0909 - accuracy: 0.9726 - val_loss: 0.0346 - val_accuracy: 0.9930\n",
      "Epoch 49/50\n",
      "525/525 [==============================] - 13s 26ms/step - loss: 0.0910 - accuracy: 0.9730 - val_loss: 0.0337 - val_accuracy: 0.9940\n",
      "Epoch 50/50\n",
      "525/525 [==============================] - 13s 26ms/step - loss: 0.0909 - accuracy: 0.9734 - val_loss: 0.0340 - val_accuracy: 0.9939\n"
     ]
    }
   ],
   "source": [
    "#This isn't likely to take long, so we'll use a large epoch.  Also, fitting things into memory isn't gonna be a problem, so batch size of 64 should be fine\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "\n",
    "#Trains the model\n",
    "history = model.fit_generator(augment.flow(X_train,y_train, batch_size=batch_size),  #Retrieves the augmented images from the ImageDataGenerator\n",
    "                              epochs = epochs, \n",
    "                              steps_per_epoch=len(X_train) // batch_size, #So we get the entire training set per epoch\n",
    "                              validation_data = (X_val,y_val),\n",
    "                              verbose = 1, \n",
    "                              use_multiprocessing = True, #Use multiple CPUs. \n",
    "                              workers = 2                 #Kaggle gives you two CPU cores when you use GPU\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 3.356061,
     "end_time": "2021-01-10T17:57:08.372866",
     "exception": false,
     "start_time": "2021-01-10T17:57:05.016805",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Its getting high accuracy; definitely some learning going on.  Another interesting facet is that the validation loss is much less than the training loss.  This is because we did not augment the validation dataset, and as a result the validation images are much easier to predict than the augmented training images.  \n",
    "\n",
    "Let's quickly visualize how it did over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T17:57:14.662588Z",
     "iopub.status.busy": "2021-01-10T17:57:14.655242Z",
     "iopub.status.idle": "2021-01-10T17:57:14.868482Z",
     "shell.execute_reply": "2021-01-10T17:57:14.869052Z"
    },
    "papermill": {
     "duration": 3.338707,
     "end_time": "2021-01-10T17:57:14.869216",
     "exception": false,
     "start_time": "2021-01-10T17:57:11.530509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f06aa312210>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plots accuracy and loss across epochs\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['Accuracy', 'Loss', \"Validation Accuracy\", \"Validation Loss\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 3.380201,
     "end_time": "2021-01-10T17:57:21.409056",
     "exception": false,
     "start_time": "2021-01-10T17:57:18.028855",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As you can see it improved really quickly over a few epochs, then slowed down.  Ends up with a pretty high accuracy.  Let's see if there are any numbers in particular that it has trouble with (at least on the validation set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T17:57:27.863458Z",
     "iopub.status.busy": "2021-01-10T17:57:27.862399Z",
     "iopub.status.idle": "2021-01-10T17:57:28.368827Z",
     "shell.execute_reply": "2021-01-10T17:57:28.369454Z"
    },
    "papermill": {
     "duration": 3.691864,
     "end_time": "2021-01-10T17:57:28.369636",
     "exception": false,
     "start_time": "2021-01-10T17:57:24.677772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[816   0   1   0   0   0   1   1   1   2]\n",
      " [  0 965   0   0   0   0   0   0   0   0]\n",
      " [  1   1 842   1   0   0   0   0   2   0]\n",
      " [  0   0   0 861   0   1   1   0   3   0]\n",
      " [  0   0   0   0 821   0   1   1   0   2]\n",
      " [  0   0   0   0   0 805   2   0   0   2]\n",
      " [  0   0   0   0   0   1 771   0   0   0]\n",
      " [  0   1   6   1   2   0   0 859   0   6]\n",
      " [  0   0   0   0   0   1   0   0 778   2]\n",
      " [  0   0   0   0   2   1   0   1   3 831]]\n"
     ]
    }
   ],
   "source": [
    "#Makes predictions on the validation set \n",
    "validation_predictions = model.predict_classes(X_val)\n",
    "\n",
    "#Sets up a confusion matrix\n",
    "confusion = confusion_matrix(validation_predictions,y_val.idxmax(axis=1))\n",
    "\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 3.124977,
     "end_time": "2021-01-10T17:57:35.403181",
     "exception": false,
     "start_time": "2021-01-10T17:57:32.278204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Looks pretty good.  No particular false classification really stands out.  Now, we'll make predictions on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T17:57:42.442983Z",
     "iopub.status.busy": "2021-01-10T17:57:42.441549Z",
     "iopub.status.idle": "2021-01-10T17:57:44.202278Z",
     "shell.execute_reply": "2021-01-10T17:57:44.201706Z"
    },
    "papermill": {
     "duration": 5.400785,
     "end_time": "2021-01-10T17:57:44.202405",
     "exception": false,
     "start_time": "2021-01-10T17:57:38.801620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 9 0 3]\n"
     ]
    }
   ],
   "source": [
    "#Pre-process the testing data\n",
    "test = normalizeANDreshape(test, 0, 255)\n",
    "\n",
    "#Makes class predictions on the test set\n",
    "predictions = model.predict_classes(test)\n",
    "\n",
    "print(predictions[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 3.181291,
     "end_time": "2021-01-10T17:57:50.532192",
     "exception": false,
     "start_time": "2021-01-10T17:57:47.350901",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Quick conclusion:\n",
    "\n",
    "This is an example of a simple CNN.  These images are pretty basic and don't have too much noise/other things going on aside from the numbers, which makes for a pretty easy classification target.  99% accuracy for this dataset is pretty common, especially with CNNs for which is this pretty much an ideal dataset.  \n",
    "\n",
    "That said, we still need to make and sumbit the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-10T17:57:57.087854Z",
     "iopub.status.busy": "2021-01-10T17:57:57.085931Z",
     "iopub.status.idle": "2021-01-10T17:57:57.372728Z",
     "shell.execute_reply": "2021-01-10T17:57:57.372128Z"
    },
    "papermill": {
     "duration": 3.517741,
     "end_time": "2021-01-10T17:57:57.372856",
     "exception": false,
     "start_time": "2021-01-10T17:57:53.855115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Makes an Id column for the submission\n",
    "#Should just be int's between 1 and the length of the testing set\n",
    "Id = []\n",
    "for i in range(len(test)):\n",
    "    Id.append(i+1)\n",
    "\n",
    "    \n",
    "#Outputs the submission\n",
    "output = pd.DataFrame({'ImageID': Id, 'Label': predictions})\n",
    "output.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 3.985756,
     "end_time": "2021-01-10T17:58:04.482627",
     "exception": false,
     "start_time": "2021-01-10T17:58:00.496871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 709.280439,
   "end_time": "2021-01-10T17:58:09.065547",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-10T17:46:19.785108",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
